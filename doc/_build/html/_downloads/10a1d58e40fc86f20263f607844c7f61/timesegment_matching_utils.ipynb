{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Time segment matching utils\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Hugo Richard, Pierre Ablin\n# License: BSD 3 clause\n\nimport numpy as np\nimport scipy.stats as stats\n\n\ndef time_segment_matching(\n    data, win_size=10,\n):\n    \"\"\"\n    Performs time segment matching experiment\n    (code inspired from brainiak tutorials at\n    https://brainiak.org/events/ohbm2018/brainiak_sample_tutorials/10-func-align.html)\n\n    Parameters\n    ----------\n    data: array of shape (n_subjects, n_components, n_timeframes)\n        Input shared responses\n    Returns\n    -------\n    cv_score: np array of shape (n_subjects)\n        Per-subject accuracy\n    \"\"\"\n    # Pull out shape information\n    n_subjs = len(data)\n    (n_features, n_TR) = data[0].shape  # Voxel/feature by timepoint\n\n    # How many segments are there (account for edges)\n    n_seg = n_TR - win_size\n\n    # mysseg prediction prediction\n    train_data = np.zeros((n_features * win_size, n_seg))\n\n    # Concatenate the data across participants\n    for ppt_counter in range(n_subjs):\n        for window_counter in range(win_size):\n            train_data[\n                window_counter\n                * n_features : (window_counter + 1)\n                * n_features,\n                :,\n            ] += data[ppt_counter][:, window_counter : window_counter + n_seg]\n\n    # Iterate through the participants, leaving one out\n    accuracy = np.zeros(shape=n_subjs)\n    for ppt_counter in range(n_subjs):\n\n        # Preset\n        test_data = np.zeros((n_features * win_size, n_seg))\n\n        for window_counter in range(win_size):\n            test_data[\n                window_counter\n                * n_features : (window_counter + 1)\n                * n_features,\n                :,\n            ] = data[ppt_counter][:, window_counter : (window_counter + n_seg)]\n\n        # Take this participant data away\n        train_ppts = stats.zscore((train_data - test_data), axis=0, ddof=1)\n        test_ppts = stats.zscore(test_data, axis=0, ddof=1)\n\n        # Correlate the two data sets\n        corr_mtx = test_ppts.T.dot(train_ppts)\n\n        # If any segments have a correlation difference less than the window size and they aren't the same segments then set the value to negative infinity\n        for seg_1 in range(n_seg):\n            for seg_2 in range(n_seg):\n                if abs(seg_1 - seg_2) < win_size and seg_1 != seg_2:\n                    corr_mtx[seg_1, seg_2] = -np.inf\n\n        # Find the segement with the max value\n        rank = np.argmax(corr_mtx, axis=1)\n\n        # Find the number of segments that were matched for this participant\n        accuracy[ppt_counter] = sum(rank == range(n_seg)) / float(n_seg)\n\n    return accuracy"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}